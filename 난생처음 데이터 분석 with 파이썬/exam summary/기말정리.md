## 탐색적 데이터 분석(Exploratory Data Analysis, EDA)
은 데이터의 전체적인 특성을 이해하고 파악하는 과정입니다. 데이터를 시각화하여 그래프를 그리고 통계적 방법을 사용하여 데이터의 구조를 탐색합니다.

- 데이터 탐색: 데이터의 전반적인 특성을 파악합니다.
- 시각화: 데이터를 시각화하여 그래프를 그립니다. 히스토그램, 박스 플롯 등의 그래프를 사용합니다.
- 범주형 데이터: 문자를 숫자로 대체하여 데이터를 변환합니다. 예를 들어, 요일을 월화수 -> 1, 2, 3과 같이 변환할 수 있습니다.
- 순서형 데이터: 여성의 옷 사이즈와 같은 순서가 있는 데이터를 다룹니다. 이러한 데이터는 숫자로 표현되지만 순서를 가지고 있습니다.
- 정형과 비정형 데이터: 정형화된 데이터로 바꾸어야 하는 비정형 데이터를 처리합니다. 이는 데이터를 일관된 형식으로 변환하여 분석을 용이하수 있습니다.

# 3. 파일 입출력
---

## 1. CSV 파일
- **encoding :** 윈도우 : cp949 / 맥, 리눅스 : utf-8


```python
import csv
```


```python
# CSV 파일 열기
f = open('reference files/csv/characters.csv', 'r', encoding='cp949')

# csv.reader를 사용하여 파일 읽기
rdr = csv.reader(f)

# 한 줄씩 읽어서 두 번째 열만 출력
for line in rdr:
    print(line[1])

next(data)  # 첫 번째 줄은 건너뜁니다.
    
# 파일 닫기
f.close()
```


```python
# CSV 파일을 쓰기 모드로 열기
# 'newline' 매개변수는 빈 줄을 자동으로 삽입하지 않도록 합니다.
f = open('reference files/csv/write.csv', 'w', encoding='cp949', newline='')

# csv.writer 객체 생성
wr = csv.writer(f)

# 각 행에 데이터 작성
# 첫 번째 행은 열의 이름
wr.writerow(['ID', '이름', '상징색', '취미', '특징'])

# 나머지 행은 실제 데이터
wr.writerow(['001', '뽀로로', '파랑색', '낚시', '펭귄'])

# 파일 닫기
f.close()
```


```python
# CSV 파일을 추가 모드로 열기
# 'newline' 매개변수는 빈 줄을 자동으로 삽입하지 않도록 합니다.
f = open('reference files/csv/write.csv', 'a', encoding='cp949', newline='')

# csv.writer 객체 생성
wr = csv.writer(f)

# 추가할 데이터를 행에 작성
wr.writerow(['006', '포비', '흰색', '춤', '북극곰'])

# 파일 닫기
f.close()
```

## 2. 엑셀 파일

### 1. 파이썬으로 엑셀 파일 읽기


```python
import openpyxl
```


```python
# Excel 파일을 열고 workbook 객체 생성
wb = openpyxl.load_workbook('reference files/xlsx/characters.xlsx')
```


```python
# 워크북에 포함된 시트의 이름을 출력
print(wb.sheetnames)
```


```python
# 'Sheet1' 시트를 선택하여 해당 시트의 A1 셀의 값을 출력
sheet1 = wb['Sheet1']  # 'Sheet1' 시트 선택
print(sheet1['A1'].value)  # A1 셀의 값 출력
```

### 2. 파이썬으로 엑셀 파일 작성하기


```python
# 새로운 Excel 워크북을 생성합니다.
wb = openpyxl.Workbook()
```


```python
# Excel 워크북에 'Sheet2'라는 이름의 새 시트를 추가합니다.
wb.create_sheet('Sheet2')

# 변경된 시트 목록을 출력합니다.
print(wb.sheetnames)
```


```python
# 시트 이름을 할당하고 출력합니다
sheet1 = wb['Sheet']  # Sheet1을 '캐릭터 명단'으로 변경합니다
sheet2 = wb['Sheet2']  # Sheet2를 '인기도 조사'로 변경합니다

sheet1.title = '캐릭터 명단'  # Sheet1의 이름을 '캐릭터 명단'으로 변경합니다
sheet2.title = '인기도 조사'  # Sheet2의 이름을 '인기도 조사'로 변경합니다

print(wb.sheetnames)  # 업데이트된 시트 이름을 출력합니다
```


```python
sheet2['B1'] = '인기도 조사결과'  # Sheet2의 B1 셀에 '인기도 조사결과'를 할당합니다
print(sheet2['B1'].value)  # B1 셀의 값을 출력합니다
```


```python
copysheet = wb.copy_worksheet(sheet2)  # Sheet2를 복사하여 새 시트를 생성합니다
print(wb.sheetnames)  # 업데이트된 시트 이름을 출력합니다
```


```python
copysheet.title = 'copy'  # 복사된 시트의 이름을 'copy'로 변경합니다
print(wb.sheetnames)  # 업데이트된 시트 이름을 출력합니다
print(copysheet['B1'].value)  # 복사된 시트의 B1 셀의 값을 출력합니다
```


```python
del wb['인기도 조사']  # '인기도 조사' 시트를 삭제합니다
print(wb.sheetnames)  # 업데이트된 시트 이름을 출력합니다
```


```python
wb.save('reference files/xlsx/complete2.xlsx')  # 변경 사항을 포함한 워크북을 새 파일에 저장합니다
```

### 3. 경로로 파일 읽기


```python
# 'reference files/xlsx/대전태평/' 경로를 변수 path에 저장
path = 'reference files/xlsx/대전태평/'

# 지정된 경로(path)에 있는 모든 파일과 디렉토리 목록을 가져와 file_list에 저장
file_list = os.listdir(path)
```


```python
# file_list에서 확장자가 '.xlsx'인 파일들만 선택하여 새로운 리스트 file_list_py에 저장
file_list_py = [file for file in file_list if file.endswith('.xlsx')]
```


```python
df = pd.DataFrame() # 공백 프레임 만듬
for i in file_list_py: # 
    data = pd.read_excel(path + i) # 한개씩 데이터를 읽음
    df = pd.concat([df,data]) # 빈공백에 한개씩 읽은 데이터 concat함 (이어붙힘)
```


```python
# 기존 인덱스를 제거하고 인덱스를 새로 부여하여 데이터프레임을 재설정
# drop=True로 설정하여 기존 인덱스는 열로 추가되지 않음
df = df.reset_index(drop=True)
```

# 6. 넘파이 판다스
---

## 1. 넘파이


```python
import numpy as npy
```


```python
# ndarray 생성 
npy = npy.arange(12).reshape(4, 3)
npy.array([[1, 2, 3], [4, 5, 6]], dtype=np.int8)
npy.zeros((4, 3))    # 요소값이 모두 0
npy.ones((4, 3))     # 요소값이 모두 1
npy.full((4, 3), 2)  # 요소값이 모두 2
npy.eye(3)           # 단위행렬
```


```python
# 배열 속성 및 연산
npy.size           # 요소개수
npy.dtype          # 데이터타입
npy.shape=(3, 8)   # 모양
npy.ndim           # 차원 수
npy.flat           # 이터레이터
npy.nbytes         # 바이트 크기
npy.T              # 전치행렬
```


```python
# 배열 변환
npy.astype(dtype)
npy.flatten()
npy.reshape((shape))
npy.resize((shape))
npy.transpose() # 전치행렬과 동일
```


```python
# 배열 요소 합과 평균
npy.sum()          # 전체요소의 합
npy.sum(axis=0 or 1)  # 특정 축(axis)을 기준으로 합을 계산
npy.mean()         # 전체요소의 평균
npy.mean(axis=0 or 1)  # 특정 축(axis)을 기준으로 평균을 계산
```


```python
np.random.seed(): 난수 생성의 시드를 설정하는 함수.

np.random.randn(): 표준 정규 분포를 따르는 난수 배열을 생성하는 함수.
# (3,4) 3행4열 과 같은 형식
# d0, d1, ..., dn (optional): 난수 배열의 차원 크기를 지정하는 매개변수. 
# 여러 개의 차원 크기를 지정하면 해당 크기의 다차원 배열을 생성합니다.

np.random.randint(): 지정된 범위에서 정수 난수를 생성하는 함수.
# low: 난수를 생성할 최소값을 지정합니다.
# high (optional): 난수를 생성할 최대값을 지정합니다. 이 값은 low 이상이어야 합니다.
# size (4,3): 생성할 난수 배열의 크기를 지정합니다.

np.random.rand(): 0에서 1 사이의 난수를 생성하는 함수.
# (3,4) 3행4열 과 같은 형식
# d0, d1, ..., dn (optional): 난수 배열의 차원 크기를 지정하는 매개변수. 
# 여러 개의 차원 크기를 지정하면 해당 크기의 다차원 배열을 생성합니다.

np.linspace(): 지정된 범위에서 일정 간격의 숫자 배열을 생성하는 함수.
# start: 배열의 시작 값.
# stop: 배열의 종료 값.
# num (optional): 배열에 포함될 숫자의 개수. 기본값은 50입니다.
# endpoint (optional): stop 값을 배열에 포함할지 여부를 지정합니다. 
# 기본값은 True로, stop 값이 배열의 마지막 숫자로 포함됩니다.

np.arange(): 지정된 범위에서 일정 간격의 숫자 배열을 생성하는 함수.
# start (optional): 배열의 시작 값. 지정하지 않으면 기본값은 0입니다.
# stop: 배열의 종료 값. 이 값은 배열에 포함되지 않습니다.
# step (optional): 배열의 간격을 지정합니다. 기본값은 1입니다.
```

## 2. 판다스


```python
import pandas as pd
```


```python
# Pandas 시리즈 라이브러리 함수
pd.Series([리스트],index=[리스트]) 
pd.Series({딕셔너리}) #key => index, value=>value

pd_Series.unique() 고유값
pd_Series.count_values(sort=True or False) 고유값의 개수 , 오름차순 정렬할지 말지
pd_Series.rank(ascending=True or False,method='max' or 'min' or 'first')  
pd_Series[pd_Series.isin(['value'])] # 해당값만 출력 boolean

pd_Series = pd.Series([1, 2, 3, 4])
pd_Series = pd.Series([1, 2, 3], index=['a', 'b', 'c'])
pd_Series = pd.Series({'city': '서울', 'year': 2018})
pd_Series = pd.Series({'city': ['서울', '부산', '대전', '대구', '광주'],
         'year': [2017, 2017, 2018, 2018, 2018],
         'temp': [18, 20, 19, 21, 20]})
```


```python
# Pandas 데이터프레임 라이브러리 함수
pd.DataFrame({딕셔너리}) #키값이 열제목, 값이 해당열의 value로 들어간다
pd.DataFrame([리스트])  
#([리스트],[인덱스],[열제목]) => 1열으로 생성
#([[리스트],[리스트2],[리스트3]])=> ('리스트의 개수'행 생성) * ('리스트의 요소 개수' 열으로 생성)
pd.DataFrame(np.arange(12).reshape(4,3),columns=[리스트],index=[리스트])

시리즈 = 데이터프레임['column'] # 하나의 열은 시리즈
데이터프레임 = 데이터프레임[['column','column']] # 두개 이상의 열은 데이터프레임

pd_DataFrame.index = [리스트]
pd_DataFrame.columns = [리스트]
pd_DataFrame.loc[index_number, 'columns']
pd_DataFrame.iloc[index_number] 
pd_DataFrame.set_index('column',inplace=True or False)
pd_DataFrame.fillna(value)  # 결측값 value값으로 바꾸기
pd_DataFrame['key'] = value # value의 값을 가진 key라는 열을 추가 하거나 있으면 변경한다.
pd_DataFrame.describe()     # 데이터프레임의 요약 통계 정보를 출력합니다
pd_DataFrame.info()         # 데이터프레임의 각 열에 대한 정보를 출력합니다
pd_DataFrame.ffill()        # 누락된 값을 앞 방향으로 채웁니다.
pd_DataFrame.head(n=5)
pd_DataFrame.tail(n=5)
pd_DataFrame.rename(columns={'최저기온(°C)': 'min_temp'}, inplace=True) # 열 이름을 변경합니다
pd_DataFrame.div(other, axis='(0)index'or'(1)columns', level=None, fill_value=None)
pd_DataFrame.date_range('1/1/2000', periods=8) # '1/1/2000'부터 시작하여 8일간의 날짜를 포함하는 날짜 범위를 생성합니다.
pd_DataFrame.datetime(pd_DataFrame['columns'], format='%Y-%m-%d') # 2022-01-01 형식
pd_DataFrame.reset_index(drop=True) # drop=True로 설정하여 기존 인덱스는 열로 추가되지 않음

#기준으로 연산
pd_DataFrame.drop(index or key,axis=0 or 1,inplace=True or False)
pd_DataFrame.dropna(axis=0 or 1,inplace=True or False)

#방향으로 연산
pd_DataFrame.sort_index(axis 0 or 1, ascending=True or False,inplace=True or False)
pd_DataFrame.sort_values(by=['b', 'c'],ascending=True or False,inplace=True or False)
pd_DataFrame.rank(axis=0 or 1,ascending=True or False,method='first','max','min')
pd_DataFrame.sum(axis=0 or 1,skipna=True or False)
pd_DataFrame.mean(axis=0 or 1,skipna=True or False)
pd_DataFrame.idxmax(axis=0 or 1)
pd_DataFrame.idxmin(axis=0 or 1)

# 조건에 따라 새로운 열 'high1'을 DataFrame '데이터프레임'에 추가합니다.
# car의 값보다 크거나 같으면 True를 작으면 False를 저장한다.
pd_DataFrame['high1'] = pd_DataFrame.car >= 30

# 시리즈를 CSV 파일로 저장합니다.
# './file2.csv'는 저장할 파일의 경로와 이름을 나타냅니다.
# header=True는 열 이름을 포함하여 저장하고, index=False는 인덱스를 저장하지 않습니다.
# encoding='utf-8'은 UTF-8 인코딩을 사용하여 파일을 저장합니다.
pd_DataFrame.to_csv('./file2.csv', header=True, index=False, encoding='utf-8')

# CSV 파일을 읽어서 데이터프레임으로 변환합니다.
# './file2.csv'에서 파일을 읽어오며, sep=','는 구분자로 쉼표를 사용합니다.
pd_DataFrame = pd.read_csv('./file2.csv', sep=',')
```

# 7. 데이터 시각화
---

## 1. matplotlib


```python
import matplotlib.pyplot as plt
```


```python
str.contains(name) # name이라는 문자열을 찾음
round(number, 소수점이하자릿수) # 소수점 이하 자릿수까지 반올림
map(int, row[4:]) # 4번째 열부터 끝까지를 정수로 변환합니다.
```


```python
# '-' 부호가 제대로 표시되게 하는 설정 
matplotlib.rcParams['axes.unicode_minus'] = False
```


```python
# 'reference files/csv/age2.csv' 파일을 cp949 인코딩으로 읽어와서 DataFrame으로 저장합니다.
# 첫 번째 열을 인덱스로 지정합니다.
df = pd.read_csv('reference files/csv/age2.csv', encoding='cp949', index_col=0)
```


```python
# 통합적인 사용
plt.figure(figsize=(5, 3), dpi=300)  # 그래프의 크기를 5인치 x 3인치로 설정하고, 해상도를 300dpi로 설정합니다.
plt.subplot(row, column, index)

## 여러개를 한번에 그리기
fig, axs = plt.subplots(2,2, figsize=(5,5))
axs[0,0].hist(data[0])

plt.title('')  # 그래프 제목 설정

plt.xlabel('')  # x축 레이블 설정
plt.ylabel('')  # y축 레이블 설정

plt.xlim(1, 31)  # x축 범위 설정
plt.ylim(-7, 22)  # y축 범위 설정

plt.xticks(): x축의 눈금을 설정하는 함수입니다.
# 예시: plt.xticks(np.arange(-10, 11, 1), label = mx_station, rotation=90, size=6)  
# np.arange(-10, 11, 1): x축 눈금의 위치를 배열로 지정합니다.
# label: x축 눈금의 라벨을 배열로 지정합니다.
# rotation : labels을 90도 회전시킵니다.

plt.xticks(): x축의 눈금을 설정하는 함수입니다.
# 예시: plt.yticks(range(24), label = mx_station, rotation=90, size=6)
# np.arange(-10, 11, 1): x축 눈금의 위치를 배열로 지정합니다.
# label: x축 눈금의 라벨을 배열로 지정합니다.
# rotation : labels을 90도 회전시킵니다.

plt.legend()  # 범례 표시

plt.style.use('default')  # ggplot, classic, Solarize_Light2
plt.axis('equal') # off, on, scaled

plt.tight_layout()  # 그래프 요소들이 겹치지 않도록 설정합니다.
plt.savefig(): 그래프를 파일로 저장하는 함수입니다.
# 예시: plt.savefig("graph.png", dpi=300)
# "graph.png": 저장할 파일의 경로와 이름을 지정합니다.
# dpi=300: 이미지의 해상도를 설정합니다.

plt.show()  # 그래프 출력
```


```python
# plot 그래프 그리기
plt.plot(range(1, 32), df_Mar['max_temp'], label='최고기온', c='r')  # 최고기온 그래프
plt.plot(range(max(m)), range(max(m)), 'g') # 대각선 직선을 그립니다. (x=y)
plt.plot(high, 'hotpink')  # y축을 기준으로 최고 기온을 hotpink 색으로 그립니다
plt.plot(low, 'skyblue')  # y축으 기준으로 최저 기온을 skyblue 색으로 그립니다
plt.plot(): 선 그래프를 그리는 함수입니다.
#예시: plt.plot([1, 2, 3], [4, 5, 6], 'r--', label='Line')
# [1, 2, 3]: x 좌표 값.
# [4, 5, 6]: y 좌표 값.
# 'r--': 선 스타일. 빨간색(r)과 점선(--) 스타일을 지정합니다.
# label: 범례에 사용할 이름을 지정합니다.
# kind='bar': 세로 막대 그레프
# kind='barh': 가로 막대 그레프
# stacked=True: 누적 막대 그래프
# c="": 선 색
# lw="": 선 굵기
# ls="": 선 스타일 
# maker="": 마커 종류
# ms="": 마커 크기
# mec="": 마커 선 색
# mew="": 마커 선 굻기
# mfc="": 마커 내부 색
```


```python
# 막대 그래프
# 범위 0부터 100까지의 값을 x축으로 하고, result 리스트의 값들을 y축으로 하여 막대 그래프를 그립니다.
plt.bar(x, y, color='',width=,) # (range(101), result)
```


```python
# 수평 막대 그래프
# 범위 0부터 100까지의 값을 y축으로 하고, result 리스트의 값들을 x축으로 하여 가로 막대 그래프를 그립니다.
plt.barh(y, x, color='',height=,) # (range(101), result)
```


```python
# 히스토그램
plt.hist(): 히스토그램을 그리는 함수입니다.
# 예시: plt.hist(np.random.randn(100), bins=10, color='blue', alpha=0.5, label='Jan')
# np.random.randn(100): 정규 분포를 따르는 난수 100개.
# bins=10: 히스토그램의 막대 수.
# color='blue': 막대 색상.
# alpha=0.5 : 투명도 설정
# label='Jan' : 라벨 설정
# 막대 사이 간격 있음 rwidth=0.5, 없음 width=1

plt.hist(aug, bins=100, color='r', label='Aug')  # bins=가로축 개수, 구간의 개수 8월 기온에 대한 히스토그램을 그립니다
plt.hist(jan, bins=100, color='b', alpha=0.5, label='Jan')  # 1월 기온에 대한 히스토그램을 그립니다 (alpha값 설정으로 투명도 조절)
```


```python
# 박스 플롯 
plt.boxplot(): 상자 그림(Boxplot)을 그리는 함수입니다.
# 예시: plt.boxplot(np.random.randn(100)): 정규 분포(평균 0, 표준 편차 1)를 따르는 난수 100개를 생성합니다.
# np.random.randn(100): 상자 그림을 그릴 데이터를 지정합니다.
# showfliers : False = 표시안함, True = 표시함 (이상치 표시 여부 )
#이상치 : 희귀 값, 무시 X
#최대
# 75% : 3사분기 : 편차값
# 50% : 2사분기
# 25% : 1사분기 : 편차값
#최소
#이싱치 : 상위3퍼 하위4퍼
```


```python
# 원형 그래프를 그립니다.
plt.pie(): 파이 차트를 그리는 함수입니다.
# 예시: plt.pie([30, 20, 50], labels=['A', 'B', 'C'], autopct='%.1f%%')
# [30, 20, 50]: 각 파이 조각의 크기.
# labels: 각 조각의 라벨.
# autopct='%.1f%%': 각 조각의 비율을 표시하는 포맷. %.1f%%는 소수점 첫째 자리까지 표시합니다.

# 데이터는 size 리스트, 레이블은 ['남', '여'], 백분율 표시, 색상은 color 리스트, 시작 각도는 90도입니다.
plt.pie(size, labels=['남', '여'], autopct='%.1f%%', colors=['crimson', 'darkcyan'], startangle=90)
```


```python
# 산점도 
plt.scatter(): 산점도를 그리는 함수입니다.
# 예시: plt.scatter(np.arange(30), np.arange(30) + 3 * np.random.randn(30), c='g')
# np.arange(30): x 좌표 값.
# np.arange(30) + 3 * np.random.randn(30): y 좌표 값.
# c='g': 점의 색상을 녹색(green)으로 지정합니다.

plt.scatter(x, y,s=makersize,c=color)
```

## 2. 위키피디아


```python
# 위키피디아에서 올림픽 메달 테이블을 포함한 HTML 페이지를 가져와서 DataFrame으로 변환합니다.
# header=0은 첫 번째 행을 열 이름으로 지정하고, index_col=0은 첫 번째 열을 행 인덱스로 지정합니다.
df = pd.read_html('https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table', header=0, index_col=0)
```


```python
# summer에는 df[1]의 모든 행과 처음 다섯 개의 열의 데이터가 포함된 DataFrame 객체가 저장됩니다.
summer = df[1].iloc[:, :5]
```


```python
# DataFrame 객체 summer을 엑셀 파일로 저장합니다.
# 'reference files/xlsx/' 경로에 '하계올림픽메달.xlsx' 파일로 저장됩니다.
summer.to_excel('reference files/xlsx/하계올림픽메달.xlsx')
```

# 8. 데이터 전처리
---

## 1. 결측값 처리


```python
pd_DataFrame.replace(['-','','unknown',0] ,np.nan)
```


```python
pd_DataFrame.isna(df)
pd_DataFrame.isna(df).sum() # nan의 합을 출력
pd_DataFrame.isnull().sum() # nan의 합을 출력
```


```python
pd_DataFrame.dropna(subset=['B','C']) # 'B'열과 'C'열만 행 단위로 연산
```


```python
pd_DataFrame['C'].fillna(0)  # 'C'열의 NaN값만 0으로 변경
pd_DataFrame['C'].fillna('missing') # 문자열도 가능
pd_DataFrame.fillna(df.mean()) # NaN값을 평균값으로 대체
pd_DataFrame.fillna(method = ffill) # 'ffill'NaN 값을 그 위의 가장 가까운 유효한 값으로 채웁니다.
pd_DataFrame.fillna(method = 'bfill') # 'bfill'은 NaN 값을 그 아래의 가장 가까운 유효한 값으로 채웁니다.

fill_dict = {'A':df['A'].mean(),'B':'12/25','C':'missing'} # NAN값을 'A'열은 A의 평균, 'B' 열은 12/25,'C'열은 MISSING으로 채움
pd_DataFrame.fillna(fill_dict)
```

## 2. 이상치 처리


```python
def replace_outliers_iqr(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    series_cleaned = series.copy()
    series_cleaned[series < lower_bound] = lower_bound
    series_cleaned[series > upper_bound] = upper_bound
    return series_cleaned
```


```python
# 'level' 열의 75% 백분위수(Q3)를 계산하고 출력 (기본 axis=0 행 방향 연산)
Q3 = df2['level'].quantile(q=0.75)
print("Q3:", Q3)

# 'level' 열의 25% 백분위수(Q1)를 계산하고 출력
Q1 = df2['level'].quantile(q=0.25)
print("Q1:", Q1)

# IQR은 Q3에서 Q1을 뺀 값으로, 데이터의 중간 50% 범위를 나타냄
IQR = Q3 - Q1
print("IQR:", IQR)

# Upper Level은 Q3에서 1.5배 IQR을 더한 값으로, 이 값을 넘는 데이터는 이상치로 간주될 수 있음
upper_level = Q3 + 1.5 * IQR

# Lower Level은 Q1에서 1.5배 IQR을 뺀 값으로, 이 값을 넘는 데이터는 이상치로 간주될 수 있음
lower_level = Q1 - 1.5 * IQR

# Upper Level을 초과하는 값의 개수를 계산
(df2['level'] > upper_level).sum()

# Lower Level을 미달하는 값의 개수를 계산
(df2['level'] < lower_level).sum()

# 값 대체하기 
df3 = df2['level'].copy()
df3[df3['level'] > upper_level] = upper_level

df2 = df2['level'].copy()
df3[df3['level'] < lower_level] = lower_level
```

## 3. 정규화 표준화

### 표준화 StandardScaler

**기능:** 각 feature의 평균을 0, 분산을 1로 변환하여 데이터의 스케일을 조정합니다.  
**용도:** 데이터가 정규 분포를 따르는 경우에 주로 사용됩니다.  
### 표준화 RobustScaler

**기능:** 평균과 분산 대신 중앙값(median)과 사분위수(25%, 75%)를 사용하여 이상치에 강건한 스케일링을 수행합니다.  
**용도:** 데이터에 이상치가 많은 경우에 유용합니다.   
여기서 IQR(Interquartile Range)은 75번째 백분위수와 25번째 백분위수의 차이입니다.

### 정규화 MinMaxScaler

**기능:** 모든 데이터를 0과 1 사이에 위치하도록 스케일을 조정합니다. 데이터의 범위를 유지하면서 스케일을 조정하는 데 사용됩니다.  
**용도:** 데이터의 최소값과 최대값이 중요한 경우에 사용됩니다.  

### 정규화 Normalizer

**기능:** 각 행(row)의 유클리드 거리(norm)가 1이 되도록 데이터를 스케일링합니다. 주로 벡터 데이터의 크기를 조절할 때 사용됩니다.  
**용도:** 텍스트 처리나 딥러닝에서 주로 사용됩니다.  


```python
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import Normalizer
```


```python
scaler = StandardScaler() # RobustScaler(), MinMaxScaler(), Normalizer()

scaled = scaler.fit_transform(df) # 넘파이 배열로 반환 
# fit_transform()
# Fitting (적합화)
# 전처리 작업을 수행하기 위해 필요한 파라미터를 계산합니다. 예를 들어, 평균과 표준편차를 계산하는 등의 작업이 여기에 포함됩니다.
# 데이터를 이해하고 어떻게 전처리할 지 학습합니다.
# Transformation (변환)
# 계산된 파라미터를 사용하여 데이터를 변환합니다. 이 변환은 데이터의 스케일을 조정하거나, 특성을 조정하는 등의 작업을 수행합니다.
# 실제로 데이터의 형태를 변경하거나, 새로운 특성을 생성하거나, 누락된 데이터를 처리하는 등의 작업이 여기에 포함됩니다

# 넘파이 배열을 데이터 프레임으로 변환
df_scaled = pd.DataFrame(scaled, columns=['x1', 'x2', 'x3'])

# KDE 그래프 그리기
df_scaled.plot.kde()
plt.title('Scaler KDE')
plt.show()
```

# 9. 상관관계 분석
--- 

## 1. 상관관계와 상관계수 
.corr() : 
상관관계는 두 변수 간의 관계를 파악하는데 사용되는 중요한 개념입니다. 상관관계는 두 변수 간의 선형적인 관계의 강도를 측정하는 지표로, -1부터 1까지의 값을 가집니다.

1. 양의 상관관계
- 상관계수가 1에 가까울수록 두 변수 간에 강한 양의 선형 관계가 있음을 나타냅니다.
- 변수 X가 커질수록 변수 Y는 커진다.

2. 음의 상관관계
- 상관계수가 -1에 가까울수록 두 변수 간에 강한 음의 선형 관계가 있음을 나타냅니다.
- 변수 X가 커질수록 변수 Y는 작아진다

3. 상관관계 없음
- 상관계수가 0에 가까울수록 두 변수 간에 선형 관계가 거의 없거나 약한 관계가 있음을 나타냅니다.


```python
# 열을 기준으로 행방향으로 연산하여 상관관계를 분석한다
df.corr(method='pearson')
# method : pearson, spearman, kendall

# 스피어만 상관분석과 피어슨 상관분석의 차이점
# 피어슨 상관분석은 두 연속 변수 간의 선형관계를 측정하는 반면 
# 스피어만 상관분석은 선형인지 여부에 관계없이 변수 간의 단조연관성을 측정합니다. 
# 그리고 피어슨 상관관계가 스피어만 상관관계 본다 데이터의 이상치에 민감하게 반응합니다

# 켄달 상관분석의 특징
# 켄달 상관분석은 두 변수 간의 순위를 비교하여 연관성을 계산합니다.
# 한 변수가 증가할 때 다른 변수가 함께 증가하는 횟수와 감소하는 횟수를 측정하여 횟수의 차이를 상관계수로 표현하는 방법입니다.
# 순위로 표현할 수 있는 데이터 이거나, 표본 크기가 작거나, 데이터의 순위에 동률이 많을 때 활용합니다.
```

# 10. 회귀분석
---

회귀분석에서 원인인 X변수는 **독립변수** 결과인 Y변수는 **종속변수**

## 1. 선형회귀


```python
from statsmodels.formula.api import ols
from sklearn.linear_model import LinearRegression
import warnings
warnings.filterwarnings("ignore")
```


```python
# 데이터프레임 생성
df = pd.DataFrame({'x': x, 'y': y})

# OLS 회귀 분석 수행 
# y = 종속변수, x = 독립변수
fit = ols('y ~ x', data=df).fit()
# 종속변수 ~ 독립변수1 + 독립변수2 + 등등 

# 회귀 분석 결과 출력
print(fit.summary())
```


```python
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     29.0004      2.926      9.913      0.000      22.254      35.747
x              0.0107      0.001     16.463      0.000       0.009       0.012
============================================================================== 
Intercept : 절편
coef : 기울기

# x가 1증가 할때마다 절편(Intercept)는 0.0107 증가한다.
# P>|t| = P-value 유의 확률 0.05보다 낮으면 유의미하다는 의미를 가진다. |

```


```python
# 단순 선형 회귀분석에서는 설명력으로 설명계수(R^2)을 사용하며, 다중 선형 회귀 분석에서는 수정된 결정계수(adj.R^2)를 사용한다
```

## 2.로지스틱 회귀

1. 종속변수의 값이 0또는 1인 경우에 사용한다.


```python
from statsmodels.api import sm
import warnings
warnings.filterwarnings("ignore")
```


```python
# 데이터프레임 생성
df = pd.DataFrame({'x': x, 'y': y})

# 로지스틱 회귀분석
logis = sm.Logit.from_formula('x ~ y', data = df).fit()
# 종속변수 ~ 독립변수1 + 독립변수2 + 등등 

# 회귀 분석 결과 출력
print(logis.summary())
print(np.exp(logis.params))
```
